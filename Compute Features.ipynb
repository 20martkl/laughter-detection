{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import IPython.display\n",
    "import os\n",
    "import sys\n",
    "import audioread\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_seconds(s):\n",
    "    mins = int(s / 60)\n",
    "    secs = s - 60*mins\n",
    "    return \"%d:%0.2f\" % (mins, secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_root = \"/data/corpora/switchboard-1/swb_ms98_transcriptions/\"\n",
    "a_root = \"/data/corpora/switchboard-1/97S62/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_val_test_folders(t_root):\n",
    "    t_folders = [t_root + f for f in os.listdir(t_root) if os.path.isdir(t_root + f)]\n",
    "    t_folders.sort()\n",
    "    train_folders = t_folders[0:20]\n",
    "    val_folders = t_folders[20:25]\n",
    "    test_folders = t_folders[25:30]\n",
    "    train_folders.sort(); val_folders.sort(); test_folders.sort()\n",
    "    return (train_folders, val_folders, test_folders)\n",
    "\n",
    "def get_transcriptions_files(folder):\n",
    "    files = []\n",
    "    subfolders = [folder + \"/\" + f for f in os.listdir(folder)]\n",
    "    for f in subfolders:\n",
    "        fs = [f + \"/\" + fname for fname in os.listdir(f) if 'a-word.text' in fname and 'A' in fname]\n",
    "        files += fs\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "def get_all_transcriptions_files(folder_list):\n",
    "    files = []\n",
    "    for folder in folder_list:\n",
    "        files += get_transcriptions_files(folder)\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "def get_transcription_files_with_laughter_in_corpus(folder_list):\n",
    "    files = []\n",
    "    transcription_files = get_all_transcriptions_files(folder_list)\n",
    "    for f in transcription_files:\n",
    "        if count_laughter_instances_in_transcription_file(f) > 0:\n",
    "            files.append(f)\n",
    "    return files\n",
    "\n",
    "def count_transcription_files_with_laughter_in_corpus(folder_list):\n",
    "    return len(get_transcription_files_with_laughter_in_corpus(folder_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sph_files(folder):\n",
    "    return [folder + \"/\" + f for f in os.listdir(folder) if \".sph\" in f]\n",
    "\n",
    "def get_all_audio_files(a_root):\n",
    "    files = []\n",
    "    a_folders = [a_root + f + \"/data\" for f in os.listdir(a_root) if os.path.isdir(a_root + f)]\n",
    "    a_folders.sort()\n",
    "    for folder in a_folders:\n",
    "        files += get_sph_files(folder)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_from_file(f):\n",
    "    return (open(f).read().split(\"\\n\"))[0:-1]\n",
    "\n",
    "def get_laughter_rows_from_file(f):\n",
    "    return [l for l in get_text_from_file(f) if '[laughter]' in l]\n",
    "    #return [l for l in get_text_from_file(f) if 'laughter' in l] # allows laughter with words together\n",
    "\n",
    "def get_audio_file_from_id(d):\n",
    "    files = [f for f in all_audio_files if d in f]\n",
    "    if len(files) == 1:\n",
    "        return files[0]\n",
    "    elif len(files) > 1:\n",
    "        print \"More than 1 audio file matched id %d\" % (int(d))\n",
    "        return None\n",
    "    else:\n",
    "        print \"No audio file matched id %d\" % (int(d))\n",
    "        return None\n",
    "        \n",
    "def get_id_from_row(row):\n",
    "    return row[2:6]\n",
    "\n",
    "def get_id_from_file(f):\n",
    "    return get_id_from_row(get_text_from_file(f)[0])\n",
    "\n",
    "def get_audio_file_from_row(row):\n",
    "    return get_audio_file_from_id(get_id_from_row(row))\n",
    "\n",
    "def get_audio_file_from_transcription_text(t):\n",
    "    return get_audio_file_from_id(get_id_from_row(t[0]))\n",
    "\n",
    "def get_audio_file_from_transcription_file(f):\n",
    "    t = open(f).read().split('\\n')\n",
    "    return get_audio_file_from_id(get_id_from_row(t[0]))\n",
    "\n",
    "def get_audio_file_length(path):\n",
    "    f = audioread.audio_open(path)\n",
    "    l = f.duration\n",
    "    f.close()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_laughter_instances_in_transcription_file(f):\n",
    "    rows = get_laughter_rows_from_file(f)\n",
    "    return len(rows)\n",
    "\n",
    "def count_laughter_instances_in_corpus(folder_list):\n",
    "    transcription_files = get_all_transcriptions_files(folder_list)\n",
    "    count = 0\n",
    "    for f in transcription_files:\n",
    "        count += count_laughter_instances_in_transcription_file(f)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_audio_files_from_transcription_files(transcription_files):\n",
    "    files = []\n",
    "    for f in transcription_files:\n",
    "        files.append(get_audio_file_from_transcription_file(f))\n",
    "    files = list(set(files))\n",
    "    files.sort()\n",
    "    if None in files: files.remove(None)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_audio_files = get_all_audio_files(a_root)\n",
    "train_folders, val_folders, test_folders = get_train_val_test_folders(t_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laughter instances in training data: 9092\n",
      "Laughter instances in validation data: 1387\n",
      "Laughter instances in test data: 549\n",
      "\n",
      "Files containing laughter in training data: 1626\n",
      "Files containing laughter in validation data: 315\n",
      "Files containing laughter in test data: 144\n"
     ]
    }
   ],
   "source": [
    "print \"Laughter instances in training data: %d\" % (count_laughter_instances_in_corpus(train_folders))\n",
    "print \"Laughter instances in validation data: %d\" % (count_laughter_instances_in_corpus(val_folders))\n",
    "print \"Laughter instances in test data: %d\" % ( count_laughter_instances_in_corpus(test_folders))\n",
    "print\n",
    "print \"Files containing laughter in training data: %d\" % (count_transcription_files_with_laughter_in_corpus(train_folders))\n",
    "print \"Files containing laughter in validation data: %d\" % (count_transcription_files_with_laughter_in_corpus(val_folders))\n",
    "print \"Files containing laughter in test data: %d\" % (count_transcription_files_with_laughter_in_corpus(test_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No audio file matched id 2289\n",
      "No audio file matched id 4361\n",
      "No audio file matched id 4379\n",
      "2435\n",
      "2435\n"
     ]
    }
   ],
   "source": [
    "train_audio_files = get_audio_files_from_transcription_files(get_all_transcriptions_files(train_folders))\n",
    "val_audio_files = get_audio_files_from_transcription_files(get_all_transcriptions_files(val_folders))\n",
    "test_audio_files = get_audio_files_from_transcription_files(get_all_transcriptions_files(test_folders))\n",
    "\n",
    "print len(all_audio_files)\n",
    "print len(train_audio_files) + len(test_audio_files) + len(val_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_transcription_files = get_transcription_files_with_laughter_in_corpus(train_folders)\n",
    "val_transcription_files = get_transcription_files_with_laughter_in_corpus(val_folders)\n",
    "test_transcription_files = get_transcription_files_with_laughter_in_corpus(test_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No audio file matched id 2289\n",
      "No audio file matched id 4361\n",
      "No audio file matched id 4379\n",
      "1625\n",
      "313\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "train_audio_files = get_audio_files_from_transcription_files(train_transcription_files)\n",
    "val_audio_files = get_audio_files_from_transcription_files(val_transcription_files)\n",
    "test_audio_files = get_audio_files_from_transcription_files(test_transcription_files)\n",
    "print len(train_audio_files)\n",
    "print len(val_audio_files) \n",
    "print len(test_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_times_from_row(row):\n",
    "    return (float(row.split(' ')[1]), float(row.split(' ')[2]))\n",
    "\n",
    "def get_laughter_regions_from_file(t_file):\n",
    "    rows = get_laughter_rows_from_file(t_file)\n",
    "    times = []\n",
    "    for row in rows:\n",
    "        start, end = extract_times_from_row(row)\n",
    "        if end - start > 0.05:\n",
    "            times.append((start,end))\n",
    "    return times\n",
    "\n",
    "def get_length_from_regions_list(times):\n",
    "    return sum([end - start for start, end in times])\n",
    "    \n",
    "def get_random_speech_region_from_file(t_file, region_length):\n",
    "    audio_length = get_audio_file_length(get_audio_file_from_transcription_file(t_file))\n",
    "    contains_laughter = True\n",
    "    while(contains_laughter):\n",
    "        start = np.random.uniform(1.0, audio_length - region_length - 1.0)\n",
    "        end = start + region_length\n",
    "        if no_laughter_present(t_file,start,end):\n",
    "            contains_laughter = False\n",
    "    return (start, end)\n",
    "\n",
    "# Check if laughter is present in a region of an audio file by looking at the transcription file\n",
    "def no_laughter_present(t_file,start,end):\n",
    "    all_rows = get_text_from_file(t_file)\n",
    "    for row in all_rows:\n",
    "        region_start, region_end = extract_times_from_row(row)\n",
    "        if times_overlap(float(region_start), float(region_end), float(start), float(end)):\n",
    "            if 'laughter' in row.split(' ')[-1]:\n",
    "                return False\n",
    "    return True\n",
    "        \n",
    "def times_overlap(start1, end1, start2, end2):\n",
    "    if end1 < start2 or end2 < start1:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad with 0.5 seconds on each side of the desired region\n",
    "def clip_audio_region(y,sr,start,end,pad_amount=0.5):\n",
    "    start_sample = int((start-pad_amount)*sr)\n",
    "    end_sample = int((end+pad_amount)*sr)\n",
    "    return y[start_sample:end_sample]\n",
    "\n",
    "def write_clip_to_disk(path,y,sr):\n",
    "    librosa.output.write_wav(path,y,sr)\n",
    "    \n",
    "def compute_mfcc_features(y,sr):\n",
    "    return mfcc(y,samplerate=sr,winlen=0.025,winstep=0.01)\n",
    "\n",
    "def compute_delta_features(mfcc_feat):\n",
    "    return delta(mfcc_feat, 2)\n",
    "\n",
    "def compute_labels_per_frame(n_frames,sr,winstep=0.01,pad_amount=0.5):\n",
    "    #print \"n_frames: %d\" % (n_frames)\n",
    "    samples_per_frame = sr*winstep #80 with defaults\n",
    "    #with 0.5 seconds of padding, there should be 4000 samples of padding, so 50 frames of non-laughter \n",
    "    n_padding_frames = int(sr * pad_amount / samples_per_frame)\n",
    "    padding_frames = list(np.zeros(n_padding_frames))\n",
    "    laughter_frames = list(np.ones(n_frames - 2*n_padding_frames))\n",
    "    labels = padding_frames + laughter_frames + padding_frames\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_features_and_labels(y,sr,region,label_type,source_file_id,file_index):\n",
    "    clip = clip_audio_region(y,sr,start=region[0],end=region[1])\n",
    "    mfcc_features = compute_mfcc_features(clip,sr)\n",
    "    delta_features = compute_delta_features(mfcc_features)\n",
    "    n_frames = len(mfcc_features)\n",
    "    if label_type == 'laughter':\n",
    "        labels = compute_labels_per_frame(n_frames,sr)\n",
    "    else:\n",
    "        labels = np.zeros(n_frames)\n",
    "    return {'mfcc': mfcc_features,\n",
    "            'delta': delta_features,\n",
    "            'labels': labels,\n",
    "            'clip_type': label_type,\n",
    "            'source_file_id': source_file_id,\n",
    "            'file_index': file_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_and_store_features_and_labels(t_file, output_dir):\n",
    "    a_file = get_audio_file_from_transcription_file(t_file)\n",
    "    y,sr = librosa.load(a_file,sr=8000)\n",
    "    source_file_id = get_id_from_file(t_file)\n",
    "    laughter_regions = get_laughter_regions_from_file(t_file)\n",
    "    laughter_features_list = [compute_features_and_labels(y,sr,region,label_type='laughter',source_file_id=source_file_id,file_index=index) for index, region in enumerate(laughter_regions)]\n",
    "    \n",
    "    speech_region = get_random_speech_region_from_file(t_file, get_length_from_regions_list(laughter_regions))\n",
    "    speech_features = compute_features_and_labels(y,sr,speech_region,label_type='speech',source_file_id=source_file_id,file_index=0)\n",
    "    \n",
    "    laughter_output_file = output_dir + \"laughter_\" + source_file_id + \".pkl\"\n",
    "    speech_output_file = output_dir + \"speech_\" + source_file_id + \".pkl\"\n",
    "    \n",
    "    with open(laughter_output_file, \"wb\") as f:\n",
    "        pickle.dump(laughter_features_list, f)\n",
    "        \n",
    "    with open(speech_output_file, \"wb\") as f:\n",
    "        pickle.dump(speech_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_OUTPUT_DIR = \"/data/jrgillick/laughter/stored_features1/train_set/\"\n",
    "VALIDATION_OUTPUT_DIR = \"/data/jrgillick/laughter/stored_features1/val_set/\"\n",
    "TEST_OUTPUT_DIR = \"/data/jrgillick/laughter/stored_features1/test_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_all_features(transcription_file_list, output_dir):\n",
    "    for index, t_file in enumerate(transcription_file_list):\n",
    "        print \"Processing %d out of %d transcription files.\" % (index+1, len(transcription_file_list))\n",
    "        try:\n",
    "            compute_and_store_features_and_labels(t_file, output_dir)\n",
    "        except:\n",
    "            print \"ID %d Failed\" % (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_all_features(train_transcription_files, TRAIN_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_all_features(val_transcription_files, VAL_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 out of 144 transcription files.\n",
      "Processing 2 out of 144 transcription files.\n",
      "ID 1 Failed\n",
      "Processing 3 out of 144 transcription files.\n",
      "ID 2 Failed\n",
      "Processing 4 out of 144 transcription files.\n",
      "Processing 5 out of 144 transcription files.\n",
      "Processing 6 out of 144 transcription files.\n",
      "ID 5 Failed\n",
      "Processing 7 out of 144 transcription files.\n",
      "Processing 8 out of 144 transcription files.\n",
      "Processing 9 out of 144 transcription files.\n",
      "Processing 10 out of 144 transcription files.\n",
      "Processing 11 out of 144 transcription files.\n",
      "Processing 12 out of 144 transcription files.\n",
      "Processing 13 out of 144 transcription files.\n",
      "Processing 14 out of 144 transcription files.\n",
      "Processing 15 out of 144 transcription files.\n",
      "ID 14 Failed\n",
      "Processing 16 out of 144 transcription files.\n",
      "Processing 17 out of 144 transcription files.\n",
      "Processing 18 out of 144 transcription files.\n",
      "Processing 19 out of 144 transcription files.\n",
      "ID 18 Failed\n",
      "Processing 20 out of 144 transcription files.\n",
      "ID 19 Failed\n",
      "Processing 21 out of 144 transcription files.\n",
      "Processing 22 out of 144 transcription files.\n",
      "Processing 23 out of 144 transcription files.\n",
      "Processing 24 out of 144 transcription files.\n",
      "ID 23 Failed\n",
      "Processing 25 out of 144 transcription files.\n",
      "ID 24 Failed\n",
      "Processing 26 out of 144 transcription files.\n",
      "Processing 27 out of 144 transcription files.\n",
      "Processing 28 out of 144 transcription files.\n",
      "Processing 29 out of 144 transcription files.\n",
      "Processing 30 out of 144 transcription files.\n",
      "ID 29 Failed\n",
      "Processing 31 out of 144 transcription files.\n",
      "Processing 32 out of 144 transcription files.\n",
      "ID 31 Failed\n",
      "Processing 33 out of 144 transcription files.\n",
      "Processing 34 out of 144 transcription files.\n",
      "Processing 35 out of 144 transcription files.\n",
      "Processing 36 out of 144 transcription files.\n",
      "ID 35 Failed\n",
      "Processing 37 out of 144 transcription files.\n",
      "Processing 38 out of 144 transcription files.\n",
      "ID 37 Failed\n",
      "Processing 39 out of 144 transcription files.\n",
      "ID 38 Failed\n",
      "Processing 40 out of 144 transcription files.\n",
      "ID 39 Failed\n",
      "Processing 41 out of 144 transcription files.\n",
      "Processing 42 out of 144 transcription files.\n",
      "Processing 43 out of 144 transcription files.\n",
      "Processing 44 out of 144 transcription files.\n",
      "ID 43 Failed\n",
      "Processing 45 out of 144 transcription files.\n",
      "Processing 46 out of 144 transcription files.\n",
      "Processing 47 out of 144 transcription files.\n",
      "Processing 48 out of 144 transcription files.\n",
      "Processing 49 out of 144 transcription files.\n",
      "Processing 50 out of 144 transcription files.\n",
      "Processing 51 out of 144 transcription files.\n",
      "Processing 52 out of 144 transcription files.\n",
      "ID 51 Failed\n",
      "Processing 53 out of 144 transcription files.\n",
      "Processing 54 out of 144 transcription files.\n",
      "Processing 55 out of 144 transcription files.\n",
      "Processing 56 out of 144 transcription files.\n",
      "Processing 57 out of 144 transcription files.\n",
      "ID 56 Failed\n",
      "Processing 58 out of 144 transcription files.\n",
      "Processing 59 out of 144 transcription files.\n",
      "Processing 60 out of 144 transcription files.\n",
      "Processing 61 out of 144 transcription files.\n",
      "Processing 62 out of 144 transcription files.\n",
      "Processing 63 out of 144 transcription files.\n",
      "Processing 64 out of 144 transcription files.\n",
      "Processing 65 out of 144 transcription files.\n",
      "Processing 66 out of 144 transcription files.\n",
      "Processing 67 out of 144 transcription files.\n",
      "Processing 68 out of 144 transcription files.\n",
      "ID 67 Failed\n",
      "Processing 69 out of 144 transcription files.\n",
      "Processing 70 out of 144 transcription files.\n",
      "Processing 71 out of 144 transcription files.\n",
      "ID 70 Failed\n",
      "Processing 72 out of 144 transcription files.\n",
      "Processing 73 out of 144 transcription files.\n",
      "Processing 74 out of 144 transcription files.\n",
      "Processing 75 out of 144 transcription files.\n",
      "ID 74 Failed\n",
      "Processing 76 out of 144 transcription files.\n",
      "Processing 77 out of 144 transcription files.\n",
      "Processing 78 out of 144 transcription files.\n",
      "Processing 79 out of 144 transcription files.\n",
      "Processing 80 out of 144 transcription files.\n",
      "Processing 81 out of 144 transcription files.\n",
      "Processing 82 out of 144 transcription files.\n",
      "ID 81 Failed\n",
      "Processing 83 out of 144 transcription files.\n",
      "Processing 84 out of 144 transcription files.\n",
      "Processing 85 out of 144 transcription files.\n",
      "Processing 86 out of 144 transcription files.\n",
      "Processing 87 out of 144 transcription files.\n",
      "Processing 88 out of 144 transcription files.\n",
      "Processing 89 out of 144 transcription files.\n",
      "Processing 90 out of 144 transcription files.\n",
      "Processing 91 out of 144 transcription files.\n",
      "Processing 92 out of 144 transcription files.\n",
      "Processing 93 out of 144 transcription files.\n",
      "Processing 94 out of 144 transcription files.\n",
      "Processing 95 out of 144 transcription files.\n",
      "Processing 96 out of 144 transcription files.\n",
      "Processing 97 out of 144 transcription files.\n",
      "Processing 98 out of 144 transcription files.\n",
      "Processing 99 out of 144 transcription files.\n",
      "Processing 100 out of 144 transcription files.\n",
      "Processing 101 out of 144 transcription files.\n",
      "Processing 102 out of 144 transcription files.\n",
      "Processing 103 out of 144 transcription files.\n",
      "Processing 104 out of 144 transcription files.\n",
      "Processing 105 out of 144 transcription files.\n",
      "Processing 106 out of 144 transcription files.\n",
      "Processing 107 out of 144 transcription files.\n",
      "Processing 108 out of 144 transcription files.\n",
      "Processing 109 out of 144 transcription files.\n",
      "Processing 110 out of 144 transcription files.\n",
      "Processing 111 out of 144 transcription files.\n",
      "Processing 112 out of 144 transcription files.\n",
      "Processing 113 out of 144 transcription files.\n",
      "Processing 114 out of 144 transcription files.\n",
      "Processing 115 out of 144 transcription files.\n",
      "ID 114 Failed\n",
      "Processing 116 out of 144 transcription files.\n",
      "Processing 117 out of 144 transcription files.\n",
      "Processing 118 out of 144 transcription files.\n",
      "Processing 119 out of 144 transcription files.\n",
      "Processing 120 out of 144 transcription files.\n",
      "Processing 121 out of 144 transcription files.\n",
      "Processing 122 out of 144 transcription files.\n",
      "Processing 123 out of 144 transcription files.\n",
      "Processing 124 out of 144 transcription files.\n",
      "Processing 125 out of 144 transcription files.\n",
      "ID 124 Failed\n",
      "Processing 126 out of 144 transcription files.\n",
      "Processing 127 out of 144 transcription files.\n",
      "Processing 128 out of 144 transcription files.\n",
      "Processing 129 out of 144 transcription files.\n",
      "Processing 130 out of 144 transcription files.\n",
      "Processing 131 out of 144 transcription files.\n",
      "Processing 132 out of 144 transcription files.\n",
      "Processing 133 out of 144 transcription files.\n",
      "Processing 134 out of 144 transcription files.\n",
      "Processing 135 out of 144 transcription files.\n",
      "Processing 136 out of 144 transcription files.\n",
      "Processing 137 out of 144 transcription files.\n",
      "Processing 138 out of 144 transcription files.\n",
      "Processing 139 out of 144 transcription files.\n",
      "Processing 140 out of 144 transcription files.\n",
      "Processing 141 out of 144 transcription files.\n",
      "Processing 142 out of 144 transcription files.\n",
      "Processing 143 out of 144 transcription files.\n",
      "Processing 144 out of 144 transcription files.\n"
     ]
    }
   ],
   "source": [
    "compute_all_features(test_transcription_files, TEST_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
