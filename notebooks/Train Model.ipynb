{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "import keras.optimizers\n",
    "from keras.models import load_model\n",
    "import keras.regularizers\n",
    "from keras.regularizers import l2, l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_hash(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"/data/jrgillick/laughter/stored_features3/train_set/\"\n",
    "VAL_DIR = \"/data/jrgillick/laughter/stored_features3/val_set/\"\n",
    "TEST_DIR = \"/data/jrgillick/laughter/stored_features3/test_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_laughter_and_speech_clips(directory):\n",
    "    laughter_files = [directory + f for f in os.listdir(directory) if 'laughter' in f]\n",
    "    speech_files = [directory + f for f in os.listdir(directory) if not 'laughter' in f]\n",
    "\n",
    "    laughter_data = [load_hash(f) for f in laughter_files]\n",
    "\n",
    "    laughter_clips = []\n",
    "    for f in laughter_data:\n",
    "        for clip in f:\n",
    "            laughter_clips.append(clip)\n",
    "        \n",
    "    speech_data = [load_hash(f) for f in speech_files]\n",
    "    speech_clips = []\n",
    "    for f in speech_data:\n",
    "        for clip in f:\n",
    "            speech_clips.append(clip)\n",
    "    \n",
    "    #speech_clips = [load_hash(f) for f in speech_files]\n",
    "    \n",
    "    return (laughter_clips, speech_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_laughter_inputs(clip):\n",
    "    mfcc_feat = clip['mfcc']\n",
    "    delta_feat = clip['delta']\n",
    "    labels = clip['labels']\n",
    "    laughter_frame_indices = np.nonzero(labels)[0]\n",
    "    X = None\n",
    "    for index in laughter_frame_indices:\n",
    "        features = np.append(mfcc_feat[index-window_size:index+window_size],delta_feat[index-window_size:index+window_size])\n",
    "        #features = np.append(mfcc_feat[index-window_size:index+window_size][:,1:13],delta_feat[index-window_size:index+window_size][:,1:13])\n",
    "        if X is None:\n",
    "            X = features\n",
    "        else:\n",
    "            X = np.vstack([X,features])\n",
    "    return (X,np.ones(len(laughter_frame_indices)))\n",
    "\n",
    "def format_speech_inputs(clip):\n",
    "    mfcc_feat = clip['mfcc']\n",
    "    delta_feat = clip['delta']\n",
    "    labels = clip['labels']\n",
    "    speech_frame_indices = np.array(list(xrange(len(labels))))[window_size:-window_size]\n",
    "    X = []\n",
    "    for index in speech_frame_indices:\n",
    "        features = np.append(mfcc_feat[index-window_size:index+window_size],delta_feat[index-window_size:index+window_size])\n",
    "        #features = np.append(mfcc_feat[index-window_size:index+window_size][:,1:13],delta_feat[index-window_size:index+window_size][:,1:13])\n",
    "        X.append(features)\n",
    "    return (np.array(X),np.zeros(len(speech_frame_indices)))\n",
    "\n",
    "def format_laughter_clips(laughter_clips):\n",
    "    formatted_laughter_clips = []\n",
    "    for index, clip in enumerate(laughter_clips):\n",
    "        if index % 500 == 0: print \"formatting %d out of %d\" % (index, len(laughter_clips))\n",
    "        formatted_laughter_clips.append(format_laughter_inputs(clip))\n",
    "    return formatted_laughter_clips\n",
    "    \n",
    "def format_speech_clips(speech_clips):\n",
    "    formatted_speech_clips = []\n",
    "    for index, clip in enumerate(speech_clips):\n",
    "        if index % 500 == 0: print \"formatting %d out of %d\" % (index, len(speech_clips))\n",
    "        formatted_speech_clips.append(format_speech_inputs(clip))\n",
    "    return formatted_speech_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_data_and_labels(formatted_laughter_clips, formatted_speech_clips):\n",
    "    train_data = []; train_labels = []\n",
    "    for j in xrange(len(formatted_laughter_clips)):\n",
    "        #print \"Processing %d of %d\" % (j,len(formatted_laughter_clips))\n",
    "        clip, label = formatted_laughter_clips[j]\n",
    "        if not clip is None and not label is None:\n",
    "            for i in xrange(len(clip)):\n",
    "                train_data.append(clip[i])\n",
    "                train_labels.append(label[i])\n",
    "\n",
    "    for j in xrange(len(formatted_speech_clips)):\n",
    "        #print \"Processing %d of %d\" % (j,len(formatted_speech_clips))\n",
    "        clip, label = formatted_speech_clips[j]\n",
    "        if not clip is None and not label is None:\n",
    "            for i in xrange(len(clip)):\n",
    "                train_data.append(clip[i])\n",
    "                train_labels.append(label[i])\n",
    "                \n",
    "    return (train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_and_labels_from_dir(directory):\n",
    "    laughter_clips, speech_clips = get_laughter_and_speech_clips(directory)\n",
    "    formatted_laughter_clips = format_laughter_clips(laughter_clips)\n",
    "    formatted_speech_clips = format_speech_clips(speech_clips)\n",
    "    train_data, train_labels = format_data_and_labels(formatted_laughter_clips, formatted_speech_clips)\n",
    "    return (train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_data_and_labels_into_parts(train_data,train_labels,part_size=5):\n",
    "    train_data_parts = []\n",
    "    train_label_parts = []\n",
    "    i = 0\n",
    "    while i < len(train_data) - part_size:\n",
    "        train_data_parts.append(train_data[i:i+part_size])\n",
    "        train_label_parts.append(train_labels[i:i+part_size])\n",
    "        i += part_size\n",
    "    return (train_data_parts, train_label_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_subset(train_data_parts, train_label_parts, start, end):\n",
    "    X = np.vstack(train_data_parts[start:end])\n",
    "    y = np.hstack(train_label_parts[start:end])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting 0 out of 13626\n",
      "formatting 500 out of 13626\n",
      "formatting 1000 out of 13626\n",
      "formatting 1500 out of 13626\n",
      "formatting 2000 out of 13626\n",
      "formatting 2500 out of 13626\n",
      "formatting 3000 out of 13626\n",
      "formatting 3500 out of 13626\n",
      "formatting 4000 out of 13626\n",
      "formatting 4500 out of 13626\n",
      "formatting 5000 out of 13626\n",
      "formatting 5500 out of 13626\n",
      "formatting 6000 out of 13626\n",
      "formatting 6500 out of 13626\n",
      "formatting 7000 out of 13626\n",
      "formatting 7500 out of 13626\n",
      "formatting 8000 out of 13626\n",
      "formatting 8500 out of 13626\n",
      "formatting 9000 out of 13626\n",
      "formatting 9500 out of 13626\n",
      "formatting 10000 out of 13626\n",
      "formatting 10500 out of 13626\n",
      "formatting 11000 out of 13626\n",
      "formatting 11500 out of 13626\n",
      "formatting 12000 out of 13626\n",
      "formatting 12500 out of 13626\n",
      "formatting 13000 out of 13626\n",
      "formatting 13500 out of 13626\n",
      "formatting 0 out of 4896\n",
      "formatting 500 out of 4896\n",
      "formatting 1000 out of 4896\n",
      "formatting 1500 out of 4896\n",
      "formatting 2000 out of 4896\n",
      "formatting 2500 out of 4896\n",
      "formatting 3000 out of 4896\n",
      "formatting 3500 out of 4896\n",
      "formatting 4000 out of 4896\n",
      "formatting 4500 out of 4896\n"
     ]
    }
   ],
   "source": [
    "laughter_clips, speech_clips = get_laughter_and_speech_clips(TRAIN_DIR)\n",
    "# Remove some clips that were failing\n",
    "del laughter_clips[677]\n",
    "del laughter_clips[6079]\n",
    "del laughter_clips[7235]\n",
    "formatted_laughter_clips = format_laughter_clips(laughter_clips)\n",
    "formatted_speech_clips = format_speech_clips(speech_clips)\n",
    "train_data, train_labels = format_data_and_labels(formatted_laughter_clips, formatted_speech_clips)\n",
    "train_data_parts, train_label_parts = divide_data_and_labels_into_parts(train_data,train_labels,part_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting 0 out of 1922\n",
      "formatting 500 out of 1922\n",
      "formatting 1000 out of 1922\n",
      "formatting 1500 out of 1922\n",
      "formatting 0 out of 978\n",
      "formatting 500 out of 978\n"
     ]
    }
   ],
   "source": [
    "val_laughter_clips, val_speech_clips = get_laughter_and_speech_clips(VAL_DIR)\n",
    "val_formatted_laughter_clips = format_laughter_clips(val_laughter_clips)\n",
    "val_formatted_speech_clips = format_speech_clips(val_speech_clips)\n",
    "val_data, val_labels = format_data_and_labels(val_formatted_laughter_clips, val_formatted_speech_clips)\n",
    "val_data_parts, val_label_parts = divide_data_and_labels_into_parts(val_data,val_labels,part_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatting 0 out of 840\n",
      "formatting 500 out of 840\n",
      "formatting 0 out of 390\n"
     ]
    }
   ],
   "source": [
    "test_laughter_clips, test_speech_clips = get_laughter_and_speech_clips(TEST_DIR)\n",
    "test_formatted_laughter_clips = format_laughter_clips(test_laughter_clips)\n",
    "test_formatted_speech_clips = format_speech_clips(test_speech_clips)\n",
    "test_data, test_labels = format_data_and_labels(test_formatted_laughter_clips, test_formatted_speech_clips)\n",
    "test_data_parts, test_label_parts = divide_data_and_labels_into_parts(test_data,test_labels,part_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(600, use_bias=True,input_dim=1924))#1924\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(100, use_bias=True,input_dim=1924))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_on_parts(train_data_parts, train_label_parts, name):\n",
    "    train_data_parts, train_label_parts = shuffle(train_data_parts, train_label_parts, random_state=0)\n",
    "    i = 0\n",
    "    accs = []\n",
    "    while i < len(train_data_parts):\n",
    "        #print i\n",
    "        X_subset, y_subset = get_data_subset(train_data_parts, train_label_parts, i, i+2000)\n",
    "        model.fit(X_subset,y_subset,shuffle=True,batch_size = 500, epochs=1,verbose=False)\n",
    "        acc = model.evaluate(X_subset, y_subset,verbose=False)[1]\n",
    "        accs.append(acc)\n",
    "        #print np.mean(accs)\n",
    "        i += 2000\n",
    "    print \"%s accuracy %f\" % (name, np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_on_parts(data_parts, label_parts, name):\n",
    "    #train_data_parts, train_label_parts = shuffle(train_data_parts, train_label_parts, random_state=0)\n",
    "    i = 0\n",
    "    accs = []\n",
    "    while i < len(data_parts):\n",
    "        #if i % 10000 == 0: print i\n",
    "        X_subset, y_subset = get_data_subset(data_parts, label_parts, i, i+100)\n",
    "        #model.fit(X_subset,y_subset,shuffle=True,batch_size = 2000, epochs=1,verbose=False)\n",
    "        acc = model.evaluate(X_subset, y_subset,verbose=False)[1]\n",
    "        accs.append(acc)\n",
    "        i += 100\n",
    "    print \"%s accuracy %f \" % (name, np.mean(accs))\n",
    "    return (np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training accuracy 0.866959\n",
      "Training accuracy 0.895345\n",
      "Validation accuracy 0.874206 \n",
      "Epoch 1\n",
      "Training accuracy 0.890450\n",
      "Training accuracy 0.908512\n",
      "Validation accuracy 0.883787 \n",
      "Epoch 2\n",
      "Training accuracy 0.898714\n",
      "Training accuracy 0.913420\n",
      "Validation accuracy 0.886611 \n",
      "Epoch 3\n",
      "Training accuracy 0.903557\n",
      "Training accuracy 0.916353\n",
      "Validation accuracy 0.890764 \n",
      "Epoch 4\n",
      "Training accuracy 0.906733\n",
      "Training accuracy 0.918527\n",
      "Validation accuracy 0.892029 \n",
      "Epoch 5\n",
      "Training accuracy 0.909030\n",
      "Training accuracy 0.919899\n",
      "Validation accuracy 0.892029 \n",
      "Epoch 6\n"
     ]
    }
   ],
   "source": [
    "for epoch in xrange(25):\n",
    "    print \"Epoch %d\" % (epoch)\n",
    "    train_on_parts(train_data_parts, train_label_parts)\n",
    "    train_on_parts(val_data_parts, val_label_parts)\n",
    "    test_acc = evaluate_on_parts(test_data_parts, test_label_parts)\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        model.save('ff_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('ff_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
